{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "914ec155",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, json, argparse, yaml\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Set, Optional\n",
    "\n",
    "# ---------- tiny normalizers ----------\n",
    "# Normalize text: remove extra spaces, lowercase, strip edges\n",
    "_norm = lambda s: re.sub(r\"\\s+\",\" \",(s or \"\").strip().lower())\n",
    "\n",
    "# Normalize email: strip whitespace and lowercase\n",
    "_norm_email = lambda s: (s or \"\").strip().lower()\n",
    "\n",
    "# Normalize skills list: clean each skill, remove empties, return as set\n",
    "_norm_skills = lambda xs: { _norm(x) for x in (xs or []) if _norm(x) }\n",
    "\n",
    "# ---------- load config ONCE ----------\n",
    "def load_cfg(config_path: str) -> Dict:\n",
    "    \"\"\"Load and validate YAML configuration file.\"\"\"\n",
    "    # Get config file path and its parent directory for relative path resolution\n",
    "    cfgp = Path(config_path); base = cfgp.parent\n",
    "    \n",
    "    # Load YAML configuration safely\n",
    "    cfg = yaml.safe_load(cfgp.read_text(encoding=\"utf-8\"))\n",
    "    \n",
    "    # Validate required configuration fields exist\n",
    "    for k in [\"input_dir\", \"output_dir\", \"ground_truth_path\"]:\n",
    "        assert k in cfg, f\"Missing '{k}' in config.yaml\"\n",
    "    \n",
    "    # Resolve all paths relative to the config file location\n",
    "    paths = {\n",
    "        \"input_dir\":       (base / cfg[\"input_dir\"]).resolve(),        # Directory with resume files\n",
    "        \"output_dir\":      (base / cfg[\"output_dir\"]).resolve(),       # Output directory for results\n",
    "        \"ground_truth\":    (base / cfg[\"ground_truth_path\"]).resolve(), # Ground truth JSON file\n",
    "    }\n",
    "    \n",
    "    # Extract optional settings with defaults\n",
    "    options = {\n",
    "        \"print_each\": bool(cfg.get(\"print_each_resume\", False)),  # Print status for each file\n",
    "        \"exts\": set(cfg.get(\"exts\", [\".pdf\", \".docx\"])),         # Supported file extensions\n",
    "    }\n",
    "    \n",
    "    return {\"paths\": paths, \"options\": options}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7365e824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Class 1: simple extractor (name/email/skills) ----------\n",
    "class ResumeExtractor:\n",
    "    \"\"\"Rule-based resume parser for extracting name, email, and skills from PDF/DOCX files.\"\"\"\n",
    "    \n",
    "    def __init__(self, cfg: Dict):\n",
    "        \"\"\"Initialize with predefined skill lexicon covering major tech areas.\"\"\"\n",
    "        # Comprehensive skill lexicon: programming languages, frameworks, databases, \n",
    "        # cloud platforms, data science tools, ML libraries, DevOps tools\n",
    "        self.SKILL_LEXICON = sorted({\n",
    "            \"python\",\"java\",\"c#\",\".net\",\"javascript\",\"typescript\",\"nodejs\",\"react\",\"angular\",\n",
    "            \"sql\",\"mysql\",\"postgres\",\"postgresql\",\"mssql\",\"mongodb\",\"docker\",\"kubernetes\",\n",
    "            \"aws\",\"azure\",\"gcp\",\"pandas\",\"numpy\",\"scikit-learn\",\"pyspark\",\"spark\",\"hadoop\",\n",
    "            \"airflow\",\"mlflow\",\"tensorflow\",\"pytorch\",\"nlp\",\"machine learning\",\"deep learning\",\n",
    "            \"lstm\",\"xgboost\",\"lightgbm\",\"catboost\",\"git\",\"jenkins\",\"linux\",\"bash\",\"fastapi\",\n",
    "            \"flask\",\"django\",\"opencv\",\"transformers\",\"express\",\"node.js\",\"react.js\",\"rest\",\n",
    "            \"rest api\",\"rest apis\",\"microservices\",\"postgres\",\"postgresql\"\n",
    "        })\n",
    "\n",
    "    def _read_text(self, file_path: str) -> str:\n",
    "        \"\"\"Extract plain text from .docx or .pdf files.\"\"\"\n",
    "        p = Path(file_path); suf = p.suffix.lower()\n",
    "        \n",
    "        # Handle Word documents\n",
    "        if suf == \".docx\":\n",
    "            try:\n",
    "                from docx import Document  # Lazy import to avoid dependency issues\n",
    "                return \"\\n\".join(para.text for para in Document(str(p)).paragraphs)\n",
    "            except Exception:\n",
    "                return \"\"  # Silently handle missing library or corrupted files\n",
    "        \n",
    "        # Handle PDF documents\n",
    "        if suf == \".pdf\":\n",
    "            try:\n",
    "                import pdfplumber  # Lazy import to avoid dependency issues\n",
    "                text = []\n",
    "                with pdfplumber.open(str(p)) as pdf:\n",
    "                    for page in pdf.pages:\n",
    "                        text.append(page.extract_text() or \"\")  # Handle None returns\n",
    "                return \"\\n\".join(text)\n",
    "            except Exception:\n",
    "                return \"\"  # Silently handle missing library or corrupted files\n",
    "        \n",
    "        return \"\"  # Unsupported file type\n",
    "\n",
    "    def _extract_email(self, text: str) -> str:\n",
    "        \"\"\"Find first email address using regex pattern matching.\"\"\"\n",
    "        # Standard email regex: username@domain.tld format\n",
    "        m = re.search(r\"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\", text or \"\")\n",
    "        return m.group(0) if m else \"\"\n",
    "\n",
    "    def _extract_name(self, text: str) -> str:\n",
    "        \"\"\"Extract person's name using heuristic pattern matching.\"\"\"\n",
    "        for line in (text or \"\").splitlines():\n",
    "            line = line.strip()\n",
    "            # Look for lines that look like names: reasonable length, 2-5 words, valid characters\n",
    "            if 3 <= len(line) <= 80 and 2 <= len(line.split()) <= 5:\n",
    "                # Allow letters, spaces, hyphens, apostrophes, periods (including international chars)\n",
    "                if re.fullmatch(r\"[A-Za-zÀ-ÖØ-öø-ÿ.'\\- ]+\", line):\n",
    "                    return line  # Return first match (assume name appears early)\n",
    "        return \"\"\n",
    "\n",
    "    def _extract_skills(self, text: str) -> List[str]:\n",
    "        \"\"\"Extract skills using lexicon-based matching with word boundaries.\"\"\"\n",
    "        # Add spaces for boundary matching to avoid partial matches\n",
    "        t = \" \" + _norm(text) + \" \"\n",
    "        found = []\n",
    "        \n",
    "        # Search for each skill in the lexicon\n",
    "        for s in self.SKILL_LEXICON:\n",
    "            s_norm = \" \" + _norm(s) + \" \"  # Add boundaries to skill\n",
    "            if s_norm in t:\n",
    "                found.append(_norm(s))\n",
    "        \n",
    "        # Standardize common skill variants\n",
    "        canon = []\n",
    "        for sk in found:\n",
    "            sk = sk.replace(\"node.js\", \"nodejs\").replace(\"react.js\", \"react\")\n",
    "            sk = sk.replace(\"postgresql\", \"postgres\")\n",
    "            canon.append(sk)\n",
    "        \n",
    "        return sorted({*canon})  # Return deduplicated, sorted list\n",
    "\n",
    "    def parse_one(self, file_path: str) -> Dict:\n",
    "        \"\"\"Parse a single resume file and return extracted information.\"\"\"\n",
    "        txt = self._read_text(file_path)\n",
    "        return {\n",
    "            \"name\": self._extract_name(txt),\n",
    "            \"email\": self._extract_email(txt),\n",
    "            \"skills\": self._extract_skills(txt),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f76b5c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Class 2: evaluator + writer (adds `missing_block`, clean metrics) ----------\n",
    "class ResumeEvaluator:\n",
    "    \"\"\"Evaluates extraction results against ground truth and writes output files.\"\"\"\n",
    "    \n",
    "    def __init__(self, cfg: Dict):\n",
    "        \"\"\"Initialize evaluator with config paths and load ground truth data.\"\"\"\n",
    "        self.paths = cfg[\"paths\"]; self.options = cfg[\"options\"]\n",
    "        \n",
    "        # Create output directory if it doesn't exist\n",
    "        self.paths[\"output_dir\"].mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Load ground truth JSON file (filename -> expected data mapping)\n",
    "        self.gt: Dict[str, Dict] = json.loads(self.paths[\"ground_truth\"].read_text(encoding=\"utf-8\"))\n",
    "        \n",
    "        # Initialize evaluation metrics counters\n",
    "        self.n_name=self.n_email=self.ok_name=self.ok_email=0  # Name/email accuracy counters\n",
    "        self.tp=self.fp=self.fn=0  # True positive, false positive, false negative for skills\n",
    "\n",
    "    def _missing_block(self, extracted: Dict, gt: Dict) -> Dict:\n",
    "        \"\"\"Compare extracted data with ground truth and identify missing fields.\"\"\"\n",
    "        miss = {}\n",
    "        \n",
    "        # Check if name matches (normalized comparison)\n",
    "        if _norm(extracted.get(\"name\")) != _norm(gt.get(\"name\")):\n",
    "            miss[\"name\"] = gt.get(\"name\")\n",
    "        \n",
    "        # Check if email matches (normalized comparison)\n",
    "        if _norm_email(extracted.get(\"email\")) != _norm_email(gt.get(\"email\")):\n",
    "            miss[\"email\"] = gt.get(\"email\")\n",
    "        \n",
    "        # Compare skills sets and find missing ones\n",
    "        exs, gts = _norm_skills(extracted.get(\"skills\")), _norm_skills(gt.get(\"skills\"))\n",
    "        lack = sorted(gts - exs)  # Skills in ground truth but not extracted\n",
    "        if lack: \n",
    "            miss[\"skills\"] = lack\n",
    "        \n",
    "        return miss, exs, gts\n",
    "\n",
    "    def _update_metrics(self, exs:Set[str], gts:Set[str], name_ok:bool, email_ok:bool):\n",
    "        \"\"\"Update evaluation metrics based on comparison results.\"\"\"\n",
    "        # Update name/email counters\n",
    "        self.n_name+=1; self.n_email+=1\n",
    "        if name_ok: self.ok_name+=1\n",
    "        if email_ok: self.ok_email+=1\n",
    "        \n",
    "        # Update skills metrics using micro-averaging approach\n",
    "        inter = len(exs & gts)  # Intersection: correctly identified skills\n",
    "        self.tp += inter  # True positives\n",
    "        self.fp += max(0, len(exs)-inter)  # False positives: extracted but not in ground truth\n",
    "        self.fn += max(0, len(gts)-inter)  # False negatives: in ground truth but not extracted\n",
    "\n",
    "    def process_one(self, file_path: str, extracted: Dict) -> bool:\n",
    "        \"\"\"Process one resume: compare with ground truth, update metrics, write output.\"\"\"\n",
    "        fname = Path(file_path).name\n",
    "        gt = self.gt.get(fname)\n",
    "        \n",
    "        # Skip files not in ground truth (can't evaluate without expected results)\n",
    "        if gt is None:\n",
    "            return False\n",
    "        \n",
    "        # Compare extracted data with ground truth\n",
    "        miss, exs, gts = self._missing_block(extracted, gt)\n",
    "        \n",
    "        # Update evaluation metrics\n",
    "        self._update_metrics(\n",
    "            exs, gts,\n",
    "            _norm(extracted.get(\"name\")) == _norm(gt.get(\"name\")),\n",
    "            _norm_email(extracted.get(\"email\")) == _norm_email(gt.get(\"email\"))\n",
    "        )\n",
    "        \n",
    "        # Prepare output object with extracted data and diagnostic info\n",
    "        out_obj = {\n",
    "            \"name\": extracted.get(\"name\",\"\"),\n",
    "            \"email\": extracted.get(\"email\",\"\"),\n",
    "            \"skills\": extracted.get(\"skills\",[]),\n",
    "            \"missing_block\": miss,  # Shows what was missed (for debugging)\n",
    "        }\n",
    "        \n",
    "        # Print individual results if requested\n",
    "        if self.options[\"print_each\"]:\n",
    "            print(json.dumps({fname: out_obj}, ensure_ascii=False, indent=2))\n",
    "        \n",
    "        # Write individual result file (filename.json in output directory)\n",
    "        output_file = self.paths[\"output_dir\"] / (Path(fname).stem + \".json\")\n",
    "        output_file.write_text(\n",
    "            json.dumps(out_obj, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "        \n",
    "        return True\n",
    "\n",
    "    def finalize(self) -> Dict:\n",
    "        \"\"\"Calculate and return final evaluation metrics.\"\"\"\n",
    "        # Calculate precision, recall, F1 for skills (micro-averaged)\n",
    "        prec = self.tp/(self.tp+self.fp) if (self.tp+self.fp) else 0.0\n",
    "        rec  = self.tp/(self.tp+self.fn) if (self.tp+self.fn) else 0.0\n",
    "        f1   = 2*prec*rec/(prec+rec) if (prec+rec) else 0.0\n",
    "        \n",
    "        return {\n",
    "            \"name_accuracy\": round(self.ok_name/self.n_name,4) if self.n_name else 0.0,\n",
    "            \"email_accuracy\": round(self.ok_email/self.n_email,4) if self.n_email else 0.0,\n",
    "            \"skills_precision_micro\": round(prec,4),  # Precision: TP/(TP+FP)\n",
    "            \"skills_recall_micro\": round(rec,4),      # Recall: TP/(TP+FN)\n",
    "            \"skills_f1_micro\": round(f1,4),           # F1: harmonic mean of precision/recall\n",
    "            \"num_evaluated\": self.n_name,             # Total files processed\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26c33100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Pipeline: single place for file enumeration + run ----------\n",
    "class ResumePipeline:\n",
    "    \"\"\"Main pipeline that orchestrates resume processing from input to evaluation.\"\"\"\n",
    "    \n",
    "    def __init__(self, config_path: str):\n",
    "        \"\"\"Initialize pipeline with config and create extractor/evaluator instances.\"\"\"\n",
    "        self.cfg = load_cfg(config_path)  # Load configuration once\n",
    "        self.extractor = ResumeExtractor(self.cfg)  # Create resume parser\n",
    "        self.evaluator = ResumeEvaluator(self.cfg)  # Create evaluator/writer\n",
    "\n",
    "    def _iter_files(self):\n",
    "        \"\"\"Get list of resume files to process based on config settings.\"\"\"\n",
    "        d = self.cfg[\"paths\"][\"input_dir\"]  # Input directory from config\n",
    "        exts = self.cfg[\"options\"][\"exts\"]  # Allowed file extensions\n",
    "        # Return sorted list of files matching supported extensions\n",
    "        return [p for p in sorted(Path(d).glob(\"*\")) if p.suffix.lower() in exts]\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Execute the complete pipeline: extract -> evaluate -> report results.\"\"\"\n",
    "        # Process each resume file\n",
    "        for p in self._iter_files():\n",
    "            extracted = self.extractor.parse_one(str(p))  # Extract data from resume\n",
    "            self.evaluator.process_one(str(p), extracted)  # Evaluate and write results\n",
    "        \n",
    "        # Print final evaluation metrics as JSON\n",
    "        print(json.dumps(self.evaluator.finalize(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d133375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"resume_alice.pdf\": {\n",
      "    \"name\": \"Alice Johnson\",\n",
      "    \"email\": \"alice.johnson@example.com\",\n",
      "    \"skills\": [\n",
      "      \"aws\",\n",
      "      \"docker\",\n",
      "      \"git\",\n",
      "      \"machine learning\",\n",
      "      \"pandas\",\n",
      "      \"python\",\n",
      "      \"scikit-learn\",\n",
      "      \"sql\"\n",
      "    ],\n",
      "    \"missing_block\": {\n",
      "      \"skills\": [\n",
      "        \"numpy\"\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"resume_brian.pdf\": {\n",
      "    \"name\": \"Brian Lee\",\n",
      "    \"email\": \"brian.lee@example.com\",\n",
      "    \"skills\": [\n",
      "      \"aws\",\n",
      "      \"docker\",\n",
      "      \"git\",\n",
      "      \"java\",\n",
      "      \"kubernetes\",\n",
      "      \"microservices\",\n",
      "      \"rest\",\n",
      "      \"rest apis\"\n",
      "    ],\n",
      "    \"missing_block\": {\n",
      "      \"skills\": [\n",
      "        \"linux\",\n",
      "        \"postgresql\",\n",
      "        \"spring boot\"\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"resume_carmen.pdf\": {\n",
      "    \"name\": \"Carmen Diaz\",\n",
      "    \"email\": \"carmen.diaz@example.com\",\n",
      "    \"skills\": [\n",
      "      \"azure\",\n",
      "      \"git\",\n",
      "      \"react\"\n",
      "    ],\n",
      "    \"missing_block\": {\n",
      "      \"skills\": [\n",
      "        \"express\",\n",
      "        \"javascript\",\n",
      "        \"mongodb\",\n",
      "        \"nodejs\",\n",
      "        \"typescript\"\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"name_accuracy\": 1.0,\n",
      "  \"email_accuracy\": 1.0,\n",
      "  \"skills_precision_micro\": 0.7895,\n",
      "  \"skills_recall_micro\": 0.625,\n",
      "  \"skills_f1_micro\": 0.6977,\n",
      "  \"num_evaluated\": 3\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# ---------- Notebook-safe main ----------\n",
    "def main(argv=None):\n",
    "    \"\"\"Main entry point with command-line argument parsing.\"\"\"\n",
    "    # Set up argument parser with config file option\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"--config\", default=\"config.yaml\", help=\"Path to YAML config file\")\n",
    "    \n",
    "    # Parse arguments (argv=None uses sys.argv by default)\n",
    "    args, _ = ap.parse_known_args(argv)\n",
    "    \n",
    "    # Create and run the pipeline with specified config\n",
    "    ResumePipeline(args.config).run()\n",
    "\n",
    "def run_from_notebook(config_path=\"config.yaml\"):\n",
    "    \"\"\"Convenience function for running from Jupyter notebooks.\"\"\"\n",
    "    # Call main() with config argument to avoid sys.argv issues in notebooks\n",
    "    main([\"--config\", config_path])\n",
    "\n",
    "# Standard Python script entry point\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b6e8b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Resume_Parser_Git",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
